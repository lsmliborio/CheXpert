{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56566ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "# to shut up tensorflow misc warnings\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras import layers                                    \n",
    "from tensorflow.keras.activations import tanh\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import ep_generator as epgen\n",
    "import builds as B\n",
    "# import scripts.gpu_setup\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "class Model_adm():\n",
    "    class Config():        \n",
    "        class RN():\n",
    "            input_shape = 1\n",
    "            eta = 1\n",
    "            positive_shots = 1\n",
    "            negative_shots = 1\n",
    "            query_shots = 1               \n",
    "            eta_reduce_factor = 1\n",
    "            eta_reduce_schedule = 0\n",
    "            batch_size = 1\n",
    "            epochs = 1\n",
    "\n",
    "    class Builds():        \n",
    "        build_RN = staticmethod(B.build_RN)\n",
    "        build_trainer = staticmethod(B.build_trainer_v2)\n",
    "        \n",
    "    def fit(self, train_data, val_data, model, target, trainer, loss_fn):        \n",
    "        B.setSeed()\n",
    "        \n",
    "        positive_shots = self.Config.RN.positive_shots\n",
    "        negative_shots = self.Config.RN.negative_shots\n",
    "        query_shots = self.Config.RN.query_shots\n",
    "        eta = self.Config.RN.eta\n",
    "        batch_size = self.Config.RN.batch_size\n",
    "        epochs = self.Config.RN.epochs        \n",
    "        eta_reduce_factor = self.Config.RN.eta_reduce_factor\n",
    "        eta_reduce_schedule = self.Config.RN.eta_reduce_schedule\n",
    "        \n",
    "        positive, negative = train_data[target]\n",
    "        \n",
    "        log_train = []\n",
    "        log_val = []\n",
    "        try:            \n",
    "            for epoch in trange(epochs + 1):                         \n",
    "                X, y = epgen.fetch_RN(positive, negative,\n",
    "                                      positive_shots,\n",
    "                                      negative_shots,\n",
    "                                      query_shots,\n",
    "                                      batch_size)\n",
    "                loss = (trainer([X, y, eta]))\n",
    "\n",
    "                if epoch % (epochs // 100) == 0:\n",
    "                    print(f\"epoch: {epoch:5d} │ Loss: {loss:+.3f}\")\n",
    "                    \n",
    "                if eta_reduce_schedule > 0 and epoch % eta_reduce_schedule == 0 and epoch > 0:\n",
    "                    eta *= eta_reduce_factor\n",
    "                    print(f\"\\n\\nREDUCING ETA TO... {eta:.6f}\", end='\\n\\n')        \n",
    "                    \n",
    "                \n",
    "                # validation log                \n",
    "                if epoch % (epochs // 10) == 0:\n",
    "                    log_train_mid = []\n",
    "                    log_val_mid = []\n",
    "                    \n",
    "                    train_positive, train_negative = train_data[target]\n",
    "                    val_positive, val_negative = val_data[target]\n",
    "                    for i in range(20):                         \n",
    "                        X_train, y_train = epgen.fetch_RN(train_positive, train_negative,\n",
    "                                                          positive_shots,\n",
    "                                                          negative_shots,\n",
    "                                                          query_shots,\n",
    "                                                          batch_size)\n",
    "                        X_val, y_val = epgen.fetch_RN(val_positive, val_negative,\n",
    "                                                      positive_shots,\n",
    "                                                      negative_shots,\n",
    "                                                      query_shots,\n",
    "                                                      batch_size)\n",
    "                        pred_train = model.predict(X_train)\n",
    "                        pred_val = model.predict(X_val)\n",
    "                        \n",
    "                        train_loss = loss_fn(y_train, pred_train)\n",
    "                        val_loss = loss_fn(y_val, pred_val)      \n",
    "                        \n",
    "                        log_train_mid.append(train_loss)\n",
    "                        log_val_mid.append(val_loss)\n",
    "\n",
    "                    log_train.append((K.eval(tf.reduce_mean(log_train_mid))))    \n",
    "                    log_val.append(K.eval(tf.reduce_mean(log_val_mid)))\n",
    "\n",
    "            return log_train, log_val\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"Training interrupted at epoch {epoch}.\")\n",
    "            return log_train, log_val         \n",
    "\n",
    "    \n",
    "    def evaluate(self, data, target, model, iterations):    \n",
    "        B.setSeed()\n",
    "        \n",
    "        batch_size = self.Config.RN.batch_size\n",
    "        positive_shots = self.Config.RN.positive_shots\n",
    "        negative_shots = self.Config.RN.negative_shots\n",
    "        query_shots = self.Config.RN.query_shots\n",
    "        positive, negative = data[target]\n",
    "        \n",
    "        print(\"Evaluating model...\\n\")\n",
    "        log = []\n",
    "        for i in trange(iterations):\n",
    "            inner_log = []            \n",
    "            for i in range(10):                                \n",
    "                X, y = epgen.fetch_RN(positive, negative,\n",
    "                                       positive_shots,\n",
    "                                       negative_shots,\n",
    "                                       query_shots,\n",
    "                                       batch_size)            \n",
    "\n",
    "#                 pred = K.eval(model(X, training=True))\n",
    "                pred = model.predict(X)\n",
    "                test = np.argmax(y, axis=2) == np.argmax(pred, axis=2)    \n",
    "                test = (test * 1)\n",
    "\n",
    "                inner_log.append(test)\n",
    "            log.append(np.array(inner_log).mean())\n",
    "\n",
    "        log = np.array(log)\n",
    "        mean_acc = log.mean()\n",
    "        std_acc = log.std()\n",
    "        \n",
    "        print(f\"Accuracy: {round(mean_acc*100, 2)} +- {round(std_acc*1.96*100, 2)}%\")            \n",
    "\n",
    "        return mean_acc, std_acc\n",
    "    \n",
    "    \n",
    "    def evaluateTransfer(self, data, target, model, iterations, batch_size, \n",
    "                         positive_shots, negative_shots, query_shots):    \n",
    "        B.setSeed()\n",
    "        positive, negative = data[target]\n",
    "        print(\"Evaluating model...\\n\")\n",
    "        log = []\n",
    "        for i in trange(iterations):\n",
    "            inner_log = []            \n",
    "            for i in range(10):                                \n",
    "                X, y = epgen.fetch_RN(positive, negative,\n",
    "                                       positive_shots,\n",
    "                                       negative_shots,\n",
    "                                       query_shots,\n",
    "                                       batch_size)            \n",
    "\n",
    "                pred = model.predict(X)\n",
    "                test = np.argmax(y, axis=2) == np.argmax(pred, axis=2)    \n",
    "                test = (test * 1)\n",
    "\n",
    "                inner_log.append(test)\n",
    "            log.append(np.array(inner_log).mean())\n",
    "\n",
    "        log = np.array(log)\n",
    "        mean_acc = log.mean()\n",
    "        std_acc = log.std()\n",
    "        \n",
    "        print(f\"Accuracy: {round(mean_acc*100, 2)} +- {round(std_acc*1.96*100, 2)}%\")            \n",
    "\n",
    "        return mean_acc, std_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a3b645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes\n",
      "Enlarged Cardiomediastinum (10798, 1) (21638, 1)\n",
      "Cardiomegaly (27000, 1) (11116, 1)\n",
      "Lung Opacity (105581, 1) (6599, 1)\n",
      "Lung Lesion (9186, 1) (1270, 1)\n",
      "Edema (52246, 1) (20726, 1)\n",
      "Consolidation (14783, 1) (28097, 1)\n",
      "Pneumonia (6039, 1) (2799, 1)\n",
      "Atelectasis (33376, 1) (1328, 1)\n",
      "Pneumothorax (19448, 1) (56341, 1)\n",
      "Pleural Effusion (86187, 1) (35396, 1)\n",
      "Pleural Other (3523, 1) (316, 1)\n",
      "Fracture (9040, 1) (2512, 1)\n",
      "Support Devices (116001, 1) (6137, 1)\n",
      "\n",
      "Validation shapes\n",
      "Enlarged Cardiomediastinum (109, 1) (125, 1)\n",
      "Cardiomegaly (68, 1) (166, 1)\n",
      "Lung Opacity (126, 1) (108, 1)\n",
      "Edema (45, 1) (189, 1)\n",
      "Consolidation (33, 1) (201, 1)\n",
      "Atelectasis (80, 1) (154, 1)\n",
      "Pleural Effusion (67, 1) (167, 1)\n",
      "Support Devices (107, 1) (127, 1)\n"
     ]
    }
   ],
   "source": [
    "MAIN_PATH = \"CheXpert-v1.0-small\"\n",
    "TRAIN_PATH = os.path.join(MAIN_PATH, 'train')\n",
    "VALID_PATH = os.path.join(MAIN_PATH, 'valid')\n",
    "TRAIN_CSV_PATH = os.path.join(MAIN_PATH, 'train_v3.csv')\n",
    "VALID_CSV_PATH = os.path.join(MAIN_PATH, 'valid_v3.csv')\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "df_valid = pd.read_csv(VALID_CSV_PATH)\n",
    "\n",
    "full_data_train = epgen.get_full_data(TRAIN_CSV_PATH)\n",
    "full_data_valid = epgen.get_full_data(VALID_CSV_PATH)\n",
    "\n",
    "print(\"Train shapes\")\n",
    "for key in full_data_train.keys():\n",
    "    p, n = full_data_train[key]\n",
    "    print(key, p.shape, n.shape)\n",
    "    \n",
    "print(\"\\nValidation shapes\")\n",
    "del_keys = []\n",
    "for key in full_data_valid.keys():\n",
    "    p, n = full_data_valid[key]\n",
    "    \n",
    "    if p.shape[0] <= 20 or n.shape[0] <= 20:\n",
    "        del_keys.append(key)\n",
    "    else:\n",
    "        print(key, p.shape, n.shape)\n",
    "        \n",
    "for key in del_keys:\n",
    "    full_data_valid.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713839e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start model administrator object\n",
    "model_adm = Model_adm()\n",
    "builds = model_adm.Builds\n",
    "config_RN = model_adm.Config.RN\n",
    "\n",
    "# configure setup\n",
    "config_RN.input_shape = (320, 320, 1)\n",
    "config_RN.eta = 3e-4\n",
    "config_RN.positive_shots = 5\n",
    "config_RN.negative_shots = 5\n",
    "config_RN.query_shots = 3\n",
    "config_RN.batch_size = 64\n",
    "config_RN.epochs = 15000\n",
    "config_RN.eta_reduce_factor = 0.5\n",
    "config_RN.eta_reduce_schedule = 10000\n",
    "\n",
    "# generate models and trainers\n",
    "# RN = builds.build_RN(config_RN.positive_shots, \n",
    "#                      config_RN.negative_shots,\n",
    "#                      config_RN.query_shots)\n",
    "# trainer, loss_fn = builds.build_trainer(RN,\n",
    "#                                config_RN.eta,\n",
    "#                                config_RN.query_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b808460",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RelationNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_0 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " IEM (Functional)               (None, 40, 40, 64)   40416       ['input_0[0][0]',                \n",
      "                                                                  'input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]',                \n",
      "                                                                  'input_4[0][0]',                \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'input_6[0][0]',                \n",
      "                                                                  'input_7[0][0]',                \n",
      "                                                                  'input_8[0][0]',                \n",
      "                                                                  'input_9[0][0]',                \n",
      "                                                                  'input_10[0][0]',               \n",
      "                                                                  'input_11[0][0]',               \n",
      "                                                                  'input_12[0][0]']               \n",
      "                                                                                                  \n",
      " Fusion_Anom (Average)          (None, 40, 40, 64)   0           ['IEM[0][0]',                    \n",
      "                                                                  'IEM[1][0]',                    \n",
      "                                                                  'IEM[2][0]',                    \n",
      "                                                                  'IEM[3][0]',                    \n",
      "                                                                  'IEM[4][0]']                    \n",
      "                                                                                                  \n",
      " Fusion_Good (Average)          (None, 40, 40, 64)   0           ['IEM[5][0]',                    \n",
      "                                                                  'IEM[6][0]',                    \n",
      "                                                                  'IEM[7][0]',                    \n",
      "                                                                  'IEM[8][0]',                    \n",
      "                                                                  'IEM[9][0]']                    \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 40, 40, 128)  0           ['Fusion_Anom[0][0]',            \n",
      "                                                                  'Fusion_Good[0][0]']            \n",
      "                                                                                                  \n",
      " RESHAPER (Functional)          (None, 20, 20, 32)   39552       ['Fusion_Anom[0][0]',            \n",
      "                                                                  'Fusion_Good[0][0]',            \n",
      "                                                                  'IEM[10][0]',                   \n",
      "                                                                  'IEM[11][0]',                   \n",
      "                                                                  'IEM[12][0]']                   \n",
      "                                                                                                  \n",
      " CTM (Functional)               (None, 20, 20, 32)   59904       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 20, 20, 32)   0           ['RESHAPER[0][0]',               \n",
      "                                                                  'CTM[0][0]']                    \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 20, 20, 32)   0           ['RESHAPER[2][0]',               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'CTM[0][0]']                    \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 20, 20, 32)   0           ['RESHAPER[3][0]',               \n",
      "                                                                  'CTM[0][0]']                    \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 20, 20, 32)   0           ['RESHAPER[4][0]',               \n",
      "                                                                  'CTM[0][0]']                    \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 20, 20, 32)   0           ['RESHAPER[1][0]',               \n",
      "                                                                  'CTM[0][0]']                    \n",
      "                                                                                                  \n",
      " Concat_Anom_0 (Concatenate)    (None, 20, 20, 64)   0           ['multiply[0][0]',               \n",
      "                                                                  'multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " Concat_Anom_1 (Concatenate)    (None, 20, 20, 64)   0           ['multiply[0][0]',               \n",
      "                                                                  'multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " Concat_Anom_2 (Concatenate)    (None, 20, 20, 64)   0           ['multiply[0][0]',               \n",
      "                                                                  'multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " Concat_Good_0 (Concatenate)    (None, 20, 20, 64)   0           ['multiply_1[0][0]',             \n",
      "                                                                  'multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " Concat_Good_1 (Concatenate)    (None, 20, 20, 64)   0           ['multiply_1[0][0]',             \n",
      "                                                                  'multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " Concat_Good_2 (Concatenate)    (None, 20, 20, 64)   0           ['multiply_1[0][0]',             \n",
      "                                                                  'multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " RM (Functional)                (None, 1)            46721       ['Concat_Anom_0[0][0]',          \n",
      "                                                                  'Concat_Good_0[0][0]',          \n",
      "                                                                  'Concat_Anom_1[0][0]',          \n",
      "                                                                  'Concat_Good_1[0][0]',          \n",
      "                                                                  'Concat_Anom_2[0][0]',          \n",
      "                                                                  'Concat_Good_2[0][0]']          \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 3, 2)         0           ['RM[0][0]',                     \n",
      "                                                                  'RM[2][0]',                     \n",
      "                                                                  'RM[4][0]',                     \n",
      "                                                                  'RM[1][0]',                     \n",
      "                                                                  'RM[3][0]',                     \n",
      "                                                                  'RM[5][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 186,593\n",
      "Trainable params: 185,041\n",
      "Non-trainable params: 1,552\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3458b7b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Edema', 'Consolidation', 'Atelectasis', 'Pleural Effusion', 'Support Devices'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_valid.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb6b426",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ba84575042470d90e272545a400620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:     0 │ Loss: +0.724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   150 │ Loss: +0.711\n",
      "epoch:   300 │ Loss: +0.704\n",
      "epoch:   450 │ Loss: +0.697\n",
      "epoch:   600 │ Loss: +0.684\n",
      "epoch:   750 │ Loss: +0.678\n",
      "epoch:   900 │ Loss: +0.664\n",
      "epoch:  1050 │ Loss: +0.666\n",
      "epoch:  1200 │ Loss: +0.649\n",
      "epoch:  1350 │ Loss: +0.658\n",
      "epoch:  1500 │ Loss: +0.651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3300 │ Loss: +0.603\n",
      "epoch:  3450 │ Loss: +0.615\n",
      "epoch:  3600 │ Loss: +0.618\n",
      "epoch:  3750 │ Loss: +0.605\n",
      "epoch:  3900 │ Loss: +0.607\n",
      "epoch:  4050 │ Loss: +0.597\n",
      "epoch:  4200 │ Loss: +0.584\n",
      "epoch:  4350 │ Loss: +0.592\n",
      "epoch:  4500 │ Loss: +0.620\n",
      "epoch:  4650 │ Loss: +0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  5400 │ Loss: +0.564\n",
      "epoch:  5550 │ Loss: +0.556\n",
      "epoch:  5700 │ Loss: +0.551\n",
      "epoch:  5850 │ Loss: +0.556\n",
      "epoch:  6000 │ Loss: +0.549\n",
      "epoch:  6150 │ Loss: +0.551\n",
      "epoch:  6300 │ Loss: +0.539\n",
      "epoch:  6450 │ Loss: +0.536\n",
      "epoch:  6600 │ Loss: +0.548\n",
      "epoch:  6750 │ Loss: +0.536\n",
      "epoch:  6900 │ Loss: +0.543\n",
      "epoch:  7050 │ Loss: +0.533\n",
      "epoch:  7200 │ Loss: +0.531\n",
      "epoch:  7350 │ Loss: +0.524\n",
      "epoch:  7500 │ Loss: +0.534\n",
      "epoch:  7650 │ Loss: +0.549\n",
      "epoch:  7800 │ Loss: +0.541\n",
      "epoch:  7950 │ Loss: +0.542\n",
      "epoch:  8100 │ Loss: +0.544\n",
      "epoch:  8250 │ Loss: +0.550\n",
      "epoch:  8400 │ Loss: +0.535\n",
      "epoch:  8550 │ Loss: +0.531\n",
      "epoch:  8700 │ Loss: +0.530\n",
      "epoch:  8850 │ Loss: +0.520\n",
      "epoch:  9000 │ Loss: +0.531\n",
      "epoch:  9150 │ Loss: +0.529\n",
      "epoch:  9300 │ Loss: +0.531\n",
      "epoch:  9450 │ Loss: +0.533\n",
      "epoch:  9600 │ Loss: +0.515\n",
      "epoch:  9750 │ Loss: +0.521\n",
      "epoch:  9900 │ Loss: +0.522\n",
      "\n",
      "\n",
      "REDUCING ETA TO... 0.000150\n",
      "\n",
      "epoch: 10050 │ Loss: +0.533\n",
      "epoch: 10200 │ Loss: +0.518\n",
      "epoch: 10350 │ Loss: +0.512\n",
      "epoch: 10500 │ Loss: +0.532\n",
      "epoch: 10650 │ Loss: +0.519\n",
      "epoch: 10800 │ Loss: +0.531\n",
      "epoch: 10950 │ Loss: +0.522\n",
      "epoch: 11100 │ Loss: +0.523\n",
      "epoch: 11250 │ Loss: +0.524\n",
      "epoch: 11400 │ Loss: +0.517\n",
      "epoch: 11550 │ Loss: +0.527\n",
      "epoch: 11700 │ Loss: +0.517\n",
      "epoch: 11850 │ Loss: +0.512\n",
      "epoch: 12000 │ Loss: +0.524\n",
      "epoch: 12150 │ Loss: +0.526\n"
     ]
    }
   ],
   "source": [
    "target = 'Fracture'\n",
    "path = \"models/\" + target + \"_v2.h5py\"\n",
    "# config_RN.eta = 5e-5\n",
    "# config_RN.batch_size = 56\n",
    "# config_RN.epochs = 4000\n",
    "# config_RN.eta_reduce_factor = 0.75\n",
    "# config_RN.eta_reduce_schedule = 0\n",
    "train_log2, val_log2 = model_adm.fit(full_data_train, full_data_train, RN, target, trainer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4700946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_log2, label=\"train loss\")\n",
    "plt.plot(val_log2, label=\"validation loss\")\n",
    "plt.xlabel(\"Época (x2000)\")\n",
    "plt.ylabel(\"Perda\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994350f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive, negative = full_data_train[target]\n",
    "\n",
    "X, y = epgen.fetch_RN(positive, negative,\n",
    "                       4, 4, 4, 64)\n",
    "\n",
    "pred = K.eval(RN(X, training=True))\n",
    "test = np.argmax(y, axis=2) == np.argmax(pred, axis=2)    \n",
    "test = (test * 1)\n",
    "np.mean(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4332c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24344c29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_adm.evaluate(full_data_train, target, RN,  2)\n",
    "model_adm.evaluate(full_data_valid, target, RN,  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118762fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "RN.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d625a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "positive_shots = 6\n",
    "negative_shots = 6\n",
    "query_shots = 3\n",
    "transferRN = builds.build_RN(positive_shots, negative_shots, query_shots, path)\n",
    "model_adm.evaluateTransfer(full_data_valid, target, transferRN,  3, 8, positive_shots, negative_shots, query_shots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b30cd",
   "metadata": {},
   "source": [
    "RN = load_model(\"models/\" + target + \"_v1.h5py\")\n",
    "model_adm.evaluate(full_data_train, target, RN,  3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e27362",
   "metadata": {},
   "outputs": [],
   "source": [
    "RN = load_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "117827d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52864593, 0.86203796, 1.3901062 , 0.9959402 , 1.1884123 ,\n",
       "       0.7903008 , 1.0771523 , 0.7180598 , 1.1259396 , 0.6661146 ,\n",
       "       0.95519584, 0.9653425 , 1.2098596 , 0.75022316, 0.87477475,\n",
       "       0.6386132 ], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(transferRN.layers[12].layers[6].weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74b741e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52864593, 0.86203796, 1.3901062 , 0.9959402 , 1.1884123 ,\n",
       "       0.7903008 , 1.0771523 , 0.7180598 , 1.1259396 , 0.6661146 ,\n",
       "       0.95519584, 0.9653425 , 1.2098596 , 0.75022316, 0.87477475,\n",
       "       0.6386132 ], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(RN.layers[13].layers[6].weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4d263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
