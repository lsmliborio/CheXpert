{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb61d99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "# to shut up tensorflow misc warnings\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pydot\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras import layers                                    \n",
    "from tensorflow.keras.activations import tanh\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import ep_generator as epgen\n",
    "import builds as B\n",
    "# import scripts.gpu_setup\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "class Model_adm():\n",
    "    class Config():        \n",
    "        class RN():\n",
    "            input_shape = 1\n",
    "            eta = 1\n",
    "            positive_shots = 1\n",
    "            negative_shots = 1\n",
    "            query_shots = 1               \n",
    "            eta_reduce_factor = 1\n",
    "            eta_reduce_schedule = 0\n",
    "            batch_size = 1\n",
    "            epochs = 1\n",
    "\n",
    "    class Builds():        \n",
    "        build_RN = staticmethod(B.build_RN)\n",
    "        build_trainer = staticmethod(B.build_trainer_v2)\n",
    "        \n",
    "    def fit(self, train_data, val_data, model, target, trainer, loss_fn):        \n",
    "        B.setSeed()\n",
    "        \n",
    "        positive_shots = self.Config.RN.positive_shots\n",
    "        negative_shots = self.Config.RN.negative_shots\n",
    "        query_shots = self.Config.RN.query_shots\n",
    "        eta = self.Config.RN.eta\n",
    "        batch_size = self.Config.RN.batch_size\n",
    "        epochs = self.Config.RN.epochs        \n",
    "        eta_reduce_factor = self.Config.RN.eta_reduce_factor\n",
    "        eta_reduce_schedule = self.Config.RN.eta_reduce_schedule\n",
    "        \n",
    "        positive, negative = train_data[target]\n",
    "        \n",
    "        log_train = []\n",
    "        log_val = []\n",
    "        try:            \n",
    "            for epoch in trange(epochs + 1):                         \n",
    "                X, y = epgen.fetch_RN(positive, negative,\n",
    "                                      positive_shots,\n",
    "                                      negative_shots,\n",
    "                                      query_shots,\n",
    "                                      batch_size)\n",
    "                loss = (trainer([X, y, eta]))\n",
    "\n",
    "                if epoch % (epochs // 100) == 0:\n",
    "                    print(f\"epoch: {epoch:5d} â”‚ Loss: {loss:+.3f}\")\n",
    "                    \n",
    "                if eta_reduce_schedule > 0 and epoch % eta_reduce_schedule == 0 and epoch > 0:\n",
    "                    eta *= eta_reduce_factor\n",
    "                    print(f\"\\n\\nREDUCING ETA TO... {eta:.6f}\", end='\\n\\n')        \n",
    "                    \n",
    "                \n",
    "                # validation log                \n",
    "                if epoch % (epochs // 10) == 0:\n",
    "                    log_train_mid = []\n",
    "                    log_val_mid = []\n",
    "                    \n",
    "                    train_positive, train_negative = train_data[target]\n",
    "                    val_positive, val_negative = val_data[target]\n",
    "                    for i in range(20):                         \n",
    "                        X_train, y_train = epgen.fetch_RN(train_positive, train_negative,\n",
    "                                                          positive_shots,\n",
    "                                                          negative_shots,\n",
    "                                                          query_shots,\n",
    "                                                          batch_size)\n",
    "                        X_val, y_val = epgen.fetch_RN(val_positive, val_negative,\n",
    "                                                      positive_shots,\n",
    "                                                      negative_shots,\n",
    "                                                      query_shots,\n",
    "                                                      batch_size)\n",
    "                        pred_train = model.predict(X_train)\n",
    "                        pred_val = model.predict(X_val)\n",
    "                        \n",
    "                        train_loss = loss_fn(y_train, pred_train)\n",
    "                        val_loss = loss_fn(y_val, pred_val)      \n",
    "                        \n",
    "                        log_train_mid.append(train_loss)\n",
    "                        log_val_mid.append(val_loss)\n",
    "\n",
    "                    log_train.append((K.eval(tf.reduce_mean(log_train_mid))))    \n",
    "                    log_val.append(K.eval(tf.reduce_mean(log_val_mid)))\n",
    "\n",
    "            return log_train, log_val\n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"Training interrupted at epoch {epoch}.\")\n",
    "            return log_train, log_val         \n",
    "\n",
    "    \n",
    "    def evaluate(self, data, target, model, iterations):    \n",
    "        B.setSeed()\n",
    "        \n",
    "        batch_size = self.Config.RN.batch_size\n",
    "        positive_shots = self.Config.RN.positive_shots\n",
    "        negative_shots = self.Config.RN.negative_shots\n",
    "        query_shots = self.Config.RN.query_shots\n",
    "        positive, negative = data[target]\n",
    "        \n",
    "        print(\"Evaluating model...\\n\")\n",
    "        log = []\n",
    "        for i in trange(iterations):\n",
    "            inner_log = []            \n",
    "            for i in range(10):                                \n",
    "                X, y = epgen.fetch_RN(positive, negative,\n",
    "                                       positive_shots,\n",
    "                                       negative_shots,\n",
    "                                       query_shots,\n",
    "                                       batch_size)            \n",
    "\n",
    "#                 pred = K.eval(model(X, training=True))\n",
    "                pred = model.predict(X)\n",
    "                test = np.argmax(y, axis=2) == np.argmax(pred, axis=2)    \n",
    "                test = (test * 1)\n",
    "\n",
    "                inner_log.append(test)\n",
    "            log.append(np.array(inner_log).mean())\n",
    "\n",
    "        log = np.array(log)\n",
    "        mean_acc = log.mean()\n",
    "        std_acc = log.std()\n",
    "        \n",
    "        print(f\"Accuracy: {round(mean_acc*100, 2)} +- {round(std_acc*1.96*100, 2)}%\")            \n",
    "\n",
    "        return mean_acc, std_acc\n",
    "    \n",
    "    \n",
    "    def evaluateTransfer(self, data, target, model, iterations, batch_size, \n",
    "                         positive_shots, negative_shots, query_shots):    \n",
    "        B.setSeed()\n",
    "        positive, negative = data[target]\n",
    "        print(\"Evaluating model...\\n\")\n",
    "        log = []\n",
    "        for i in trange(iterations):\n",
    "            inner_log = []            \n",
    "            for i in range(10):                                \n",
    "                X, y = epgen.fetch_RN(positive, negative,\n",
    "                                       positive_shots,\n",
    "                                       negative_shots,\n",
    "                                       query_shots,\n",
    "                                       batch_size)            \n",
    "\n",
    "                pred = model.predict(X)\n",
    "                test = np.argmax(y, axis=2) == np.argmax(pred, axis=2)    \n",
    "                test = (test * 1)\n",
    "\n",
    "                inner_log.append(test)\n",
    "            log.append(np.array(inner_log).mean())\n",
    "\n",
    "        log = np.array(log)\n",
    "        mean_acc = log.mean()\n",
    "        std_acc = log.std()\n",
    "        \n",
    "        print(f\"Accuracy: {round(mean_acc*100, 2)} +- {round(std_acc*1.96*100, 2)}%\")            \n",
    "\n",
    "        return mean_acc, std_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "299d2490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes\n",
      "Enlarged Cardiomediastinum (10798, 1) (21638, 1)\n",
      "Cardiomegaly (27000, 1) (11116, 1)\n",
      "Lung Opacity (105581, 1) (6599, 1)\n",
      "Lung Lesion (9186, 1) (1270, 1)\n",
      "Edema (52246, 1) (20726, 1)\n",
      "Consolidation (14783, 1) (28097, 1)\n",
      "Pneumonia (6039, 1) (2799, 1)\n",
      "Atelectasis (33376, 1) (1328, 1)\n",
      "Pneumothorax (19448, 1) (56341, 1)\n",
      "Pleural Effusion (86187, 1) (35396, 1)\n",
      "Pleural Other (3523, 1) (316, 1)\n",
      "Fracture (9040, 1) (2512, 1)\n",
      "Support Devices (116001, 1) (6137, 1)\n",
      "\n",
      "Validation shapes\n",
      "Enlarged Cardiomediastinum (109, 1) (125, 1)\n",
      "Cardiomegaly (68, 1) (166, 1)\n",
      "Lung Opacity (126, 1) (108, 1)\n",
      "Edema (45, 1) (189, 1)\n",
      "Consolidation (33, 1) (201, 1)\n",
      "Atelectasis (80, 1) (154, 1)\n",
      "Pleural Effusion (67, 1) (167, 1)\n",
      "Support Devices (107, 1) (127, 1)\n"
     ]
    }
   ],
   "source": [
    "MAIN_PATH = \"CheXpert-v1.0-small\"\n",
    "TRAIN_PATH = os.path.join(MAIN_PATH, 'train')\n",
    "VALID_PATH = os.path.join(MAIN_PATH, 'valid')\n",
    "TRAIN_CSV_PATH = os.path.join(MAIN_PATH, 'train_v3.csv')\n",
    "VALID_CSV_PATH = os.path.join(MAIN_PATH, 'valid_v3.csv')\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH)\n",
    "df_valid = pd.read_csv(VALID_CSV_PATH)\n",
    "\n",
    "full_data_train = epgen.get_full_data(TRAIN_CSV_PATH)\n",
    "full_data_valid = epgen.get_full_data(VALID_CSV_PATH)\n",
    "\n",
    "print(\"Train shapes\")\n",
    "for key in full_data_train.keys():\n",
    "    p, n = full_data_train[key]\n",
    "    print(key, p.shape, n.shape)\n",
    "    \n",
    "print(\"\\nValidation shapes\")\n",
    "del_keys = []\n",
    "for key in full_data_valid.keys():\n",
    "    p, n = full_data_valid[key]\n",
    "    \n",
    "    if p.shape[0] <= 20 or n.shape[0] <= 20:\n",
    "        del_keys.append(key)\n",
    "    else:\n",
    "        print(key, p.shape, n.shape)\n",
    "        \n",
    "for key in del_keys:\n",
    "    full_data_valid.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d92362d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start model administrator object\n",
    "model_adm = Model_adm()\n",
    "builds = model_adm.Builds\n",
    "config_RN = model_adm.Config.RN\n",
    "\n",
    "# configure setup\n",
    "config_RN.input_shape = (320, 320, 1)\n",
    "config_RN.eta = 3e-4\n",
    "config_RN.positive_shots = 5\n",
    "config_RN.negative_shots = 5\n",
    "config_RN.query_shots = 3\n",
    "config_RN.batch_size = 64\n",
    "config_RN.epochs = 15000\n",
    "config_RN.eta_reduce_factor = 0.5\n",
    "config_RN.eta_reduce_schedule = 10000\n",
    "\n",
    "# generate models and trainers\n",
    "# RN = builds.build_RN(config_RN.positive_shots, \n",
    "#                      config_RN.negative_shots,\n",
    "#                      config_RN.query_shots)\n",
    "# trainer, loss_fn = builds.build_trainer(RN,\n",
    "#                                config_RN.eta,\n",
    "#                                config_RN.query_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05f9ccf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"RelationNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_0 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " IEM (Functional)               (None, 40, 40, 64)   40416       ['input_0[0][0]',                \n",
      "                                                                  'input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]',                \n",
      "                                                                  'input_4[0][0]',                \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'input_6[0][0]',                \n",
      "                                                                  'input_7[0][0]',                \n",
      "                                                                  'input_8[0][0]',                \n",
      "                                                                  'input_9[0][0]',                \n",
      "                                                                  'input_10[0][0]',               \n",
      "                                                                  'input_11[0][0]',               \n",
      "                                                                  'input_12[0][0]']               \n",
      "                                                                                                  \n",
      " Fusion_Anom (Average)          (None, 40, 40, 64)   0           ['IEM[0][0]',                    \n",
      "                                                                  'IEM[1][0]',                    \n",
      "                                                                  'IEM[2][0]',                    \n",
      "                                                                  'IEM[3][0]',                    \n",
      "                                                                  'IEM[4][0]']                    \n",
      "                                                                                                  \n",
      " Fusion_Good (Average)          (None, 40, 40, 64)   0           ['IEM[5][0]',                    \n",
      "                                                                  'IEM[6][0]',                    \n",
      "                                                                  'IEM[7][0]',                    \n",
      "                                                                  'IEM[8][0]',                    \n",
      "                                                                  'IEM[9][0]']                    \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_12 (InputLayer)          [(None, 320, 320, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 40, 40, 128)  0           ['Fusion_Anom[0][0]',            \n",
      "                                                                  'Fusion_Good[0][0]']            \n",
      "                                                                                                  \n",
      " RESHAPER (Functional)          (None, 20, 20, 32)   39552       ['Fusion_Anom[0][0]',            \n",
      "                                                                  'Fusion_Good[0][0]',            \n",
      "                                                                  'IEM[10][0]',                   \n",
      "                                                                  'IEM[11][0]',                   \n",
      "                                                                  'IEM[12][0]']                   \n",
      "                                                                                                  \n",
      " CTM (Functional)               (None, 20, 20, 32)   59904       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 20, 20, 32)   0           ['RESHAPER[0][0]',               \n",
      "                                                                  'CTM[0][0]']                    \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 20, 20, 32)   0           ['RESHAPER[2][0]',               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'CTM[0][0]']                    \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 20, 20, 32)   0           ['RESHAPER[3][0]',               \n",
      "                                                                  'CTM[0][0]']                    \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 20, 20, 32)   0           ['RESHAPER[4][0]',               \n",
      "                                                                  'CTM[0][0]']                    \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 20, 20, 32)   0           ['RESHAPER[1][0]',               \n",
      "                                                                  'CTM[0][0]']                    \n",
      "                                                                                                  \n",
      " Concat_Anom_0 (Concatenate)    (None, 20, 20, 64)   0           ['multiply[0][0]',               \n",
      "                                                                  'multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " Concat_Anom_1 (Concatenate)    (None, 20, 20, 64)   0           ['multiply[0][0]',               \n",
      "                                                                  'multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " Concat_Anom_2 (Concatenate)    (None, 20, 20, 64)   0           ['multiply[0][0]',               \n",
      "                                                                  'multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " Concat_Good_0 (Concatenate)    (None, 20, 20, 64)   0           ['multiply_1[0][0]',             \n",
      "                                                                  'multiply_2[0][0]']             \n",
      "                                                                                                  \n",
      " Concat_Good_1 (Concatenate)    (None, 20, 20, 64)   0           ['multiply_1[0][0]',             \n",
      "                                                                  'multiply_3[0][0]']             \n",
      "                                                                                                  \n",
      " Concat_Good_2 (Concatenate)    (None, 20, 20, 64)   0           ['multiply_1[0][0]',             \n",
      "                                                                  'multiply_4[0][0]']             \n",
      "                                                                                                  \n",
      " RM (Functional)                (None, 1)            46721       ['Concat_Anom_0[0][0]',          \n",
      "                                                                  'Concat_Good_0[0][0]',          \n",
      "                                                                  'Concat_Anom_1[0][0]',          \n",
      "                                                                  'Concat_Good_1[0][0]',          \n",
      "                                                                  'Concat_Anom_2[0][0]',          \n",
      "                                                                  'Concat_Good_2[0][0]']          \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 3, 2)         0           ['RM[0][0]',                     \n",
      "                                                                  'RM[2][0]',                     \n",
      "                                                                  'RM[4][0]',                     \n",
      "                                                                  'RM[1][0]',                     \n",
      "                                                                  'RM[3][0]',                     \n",
      "                                                                  'RM[5][0]']                     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 186,593\n",
      "Trainable params: 185,041\n",
      "Non-trainable params: 1,552\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c22049e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Enlarged Cardiomediastinum', 'Cardiomegaly', 'Lung Opacity', 'Edema', 'Consolidation', 'Atelectasis', 'Pleural Effusion', 'Support Devices'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_valid.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1266b2ad",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c143fa9d14349e3bf0e3c8bf6238754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:     0 â”‚ Loss: +0.510\n",
      "epoch:    80 â”‚ Loss: +0.528\n",
      "epoch:   160 â”‚ Loss: +0.519\n",
      "epoch:   240 â”‚ Loss: +0.513\n",
      "epoch:   400 â”‚ Loss: +0.516\n",
      "epoch:   480 â”‚ Loss: +0.512\n",
      "epoch:   560 â”‚ Loss: +0.511\n",
      "epoch:   640 â”‚ Loss: +0.527\n",
      "epoch:   720 â”‚ Loss: +0.513\n",
      "epoch:   800 â”‚ Loss: +0.511\n",
      "epoch:   880 â”‚ Loss: +0.518\n",
      "epoch:   960 â”‚ Loss: +0.509\n",
      "epoch:  1040 â”‚ Loss: +0.514\n",
      "epoch:  1120 â”‚ Loss: +0.510\n",
      "epoch:  1200 â”‚ Loss: +0.514\n",
      "epoch:  1280 â”‚ Loss: +0.514\n",
      "epoch:  1360 â”‚ Loss: +0.523\n",
      "epoch:  1440 â”‚ Loss: +0.506\n",
      "epoch:  1520 â”‚ Loss: +0.517\n",
      "epoch:  1600 â”‚ Loss: +0.509\n",
      "epoch:  1680 â”‚ Loss: +0.531\n",
      "epoch:  1760 â”‚ Loss: +0.514\n",
      "epoch:  1840 â”‚ Loss: +0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4000 â”‚ Loss: +0.509\n",
      "epoch:  4080 â”‚ Loss: +0.531\n",
      "epoch:  4160 â”‚ Loss: +0.517\n",
      "epoch:  4240 â”‚ Loss: +0.519\n",
      "epoch:  4320 â”‚ Loss: +0.508\n",
      "epoch:  4400 â”‚ Loss: +0.512\n",
      "epoch:  4480 â”‚ Loss: +0.506\n",
      "epoch:  4560 â”‚ Loss: +0.514\n",
      "epoch:  4640 â”‚ Loss: +0.516\n",
      "epoch:  4720 â”‚ Loss: +0.509\n",
      "epoch:  4800 â”‚ Loss: +0.510\n",
      "epoch:  4880 â”‚ Loss: +0.517\n",
      "epoch:  4960 â”‚ Loss: +0.504\n",
      "epoch:  5040 â”‚ Loss: +0.513\n",
      "epoch:  5120 â”‚ Loss: +0.521\n",
      "epoch:  5200 â”‚ Loss: +0.511\n",
      "epoch:  5280 â”‚ Loss: +0.510\n",
      "epoch:  5360 â”‚ Loss: +0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  7200 â”‚ Loss: +0.514\n",
      "epoch:  7280 â”‚ Loss: +0.507\n",
      "epoch:  7360 â”‚ Loss: +0.517\n",
      "epoch:  7440 â”‚ Loss: +0.517\n",
      "epoch:  7520 â”‚ Loss: +0.509\n",
      "epoch:  7600 â”‚ Loss: +0.517\n",
      "epoch:  7680 â”‚ Loss: +0.519\n",
      "epoch:  7760 â”‚ Loss: +0.510\n",
      "epoch:  7840 â”‚ Loss: +0.510\n",
      "epoch:  7920 â”‚ Loss: +0.510\n",
      "epoch:  8000 â”‚ Loss: +0.523\n"
     ]
    }
   ],
   "source": [
    "target = 'Fracture'\n",
    "path = \"models/\" + target + \"_v3.h5py\"\n",
    "# config_RN.eta = 5e-5\n",
    "# config_RN.batch_size = 56\n",
    "config_RN.epochs = 8000\n",
    "# config_RN.eta_reduce_factor = 0.75\n",
    "config_RN.eta_reduce_schedule = 0\n",
    "train_log3, val_log3 = model_adm.fit(full_data_train, full_data_train, RN, target, trainer, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "578ddb91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792b05020fb14377a41bc6ca3a47eb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.71 +- 0.31%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9770833333333333, 0.0015625000000000222)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_adm.evaluate(full_data_train, target, RN,  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7edb53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "RN.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9bc6e602",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2f4825ba2643f5860e0096084f8e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.34 +- 0.92%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9734375, 0.004687500000000011)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_shots = 8\n",
    "negative_shots = 8\n",
    "query_shots = 2\n",
    "transferRN = builds.build_RN(positive_shots, negative_shots, query_shots, path)\n",
    "model_adm.evaluateTransfer(full_data_train, target, transferRN,  2, 16, positive_shots, negative_shots, query_shots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6021e7",
   "metadata": {},
   "source": [
    "RN = load_model(\"models/\" + target + \"_v1.h5py\")\n",
    "model_adm.evaluate(full_data_train, target, RN,  3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
